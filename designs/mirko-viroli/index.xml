<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mirko Viroli on Danilo Pianini</title>
    <link>https://danysk.github.io/designs/mirko-viroli/</link>
    <description>Recent content in Mirko Viroli on Danilo Pianini</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>© Danilo Pianini</copyright>
    <lastBuildDate>Tue, 10 Sep 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://danysk.github.io/designs/mirko-viroli/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Scalability through Pulverisation: Declarative deployment reconfiguration at runtime</title>
      <link>https://danysk.github.io/portfolio/2024-fgcs-pulverization/</link>
      <pubDate>Tue, 10 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2024-fgcs-pulverization/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;&#xA;&lt;p&gt;In recent years, the infrastructure supporting the execution of situated distributed computations evolved at a fast pace.&#xA;Modern collective adaptive applications – as found in the Internet of Things, swarm robotics, and social computing –&#xA;are designed to be executed on very diverse devices and to be deployed on infrastructures composed of devices ranging&#xA;from cloud servers to wearable devices,&#xA;constituting together a cloud–edge continuum.&#xA;The availability of such an infrastructure opens to better resource utilisation and performance but, at the same time,&#xA;introduces new challenges to software designers,&#xA;as applications must be conceived to be able to adapt to changing deployment domains and conditions.&#xA;In this paper, we introduce a practical framework for the development of systems based on the concept of pulverisation,&#xA;meant to neatly separate business logic and deployment concerns, allowing applications to be defined&#xA;independently of the infrastructure they will execute upon, thus supporting scalability.&#xA;The framework is based on a domain-specific language capturing, in a declarative fashion:&#xA;pulverised application components, device capabilities, resource allocation, and (runtime re-) configuration policies.&#xA;The framework, implemented in Kotlin multiplatform and available as open source,&#xA;is then evaluated in a small-scale real-world demo and in a city-scale simulated scenario,&#xA;demonstrating the feasibility of the approach and its potential benefits&#xA;in achieving better trade-offs between performance and resource utilisation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dynamic Decentralization Domains for the Internet of Things</title>
      <link>https://danysk.github.io/portfolio/2022-ieeeinternetcomp/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2022-ieeeinternetcomp/</guid>
      <description>&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;&#xA;&lt;p&gt;The Internet of Things (IoT) and edge computing are fostering a future of ecosystems hosting complex decentralized computations that are deeply integrated with our very dynamic environments. Digitalized buildings, communities of people, and cities will be the next-generation “hardwarae and platform,” counting myriads of interconnected devices, on top of which intrinsically distributed computational processes will run and self-organize. They will spontaneously spawn, diffuse to pertinent logical/physical regions, cooperate and compete, opportunistically summon required resources, collect and analyze data, compute results, trigger distributed actions, and eventually decay. What would a programming model for such ecosystems look like? Based on research findings on self-adaptive/self-organizing systems, this article proposes design abstractions based on “dynamic decentralization domains”: regions of space opportunistically formed to support situated recognition and action. We embody the approach into a Scala application program interface (API) enacting distributed execution and show its applicability in a case study of environmental monitoring.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Self-stabilising Priority-Based Multi-Leader Election and Network Partitioning</title>
      <link>https://danysk.github.io/portfolio/2022-acsos-boundedelection/</link>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2022-acsos-boundedelection/</guid>
      <description>&lt;h4 id=&#34;slideshttpsdanyskgithubioslides-2022-acsos-boundedelection&#34;&gt;&lt;a href=&#34;https://danysk.github.io/Slides-2022-ACSOS-BoundedElection/&#34;&gt;Slides&lt;/a&gt;&lt;/h4&gt;&#xA;&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;&#xA;&lt;p&gt;A common task in situated distributed systems is the self-organising election of leaders. These leaders can be devices or software agents appointed, for instance, to coordinate the activities of other agents or processes. In this work, we focus on the multi-leader election problem in networks of asynchronous message-passing devices, which are a common model in self-organisation approaches like aggregate computing. Specifically, we introduce a novel algorithm for space- and priority-based leader election and compare it with the state of the art. We call the algorithm Bounded Election since it leverages bounding (i.e. minimisation or maximisation) of candidacy messages to drop or promote candidate leaders and ensure stabilisation. The proposed algorithm is formally proven to be self-stabilising, allows for leader prioritisation, and performs on-the-fly network partitioning (namely, as a side effect of the leader election process, the areas regulated by the leaders are also established). Also, we experimentally compare its performance together with the state of the art of leader election in aggregate computing in a variety of synthetic scenarios, showing benefits in terms of convergence time and resilience.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Partitioned integration and coordination via the self-organising coordination regions pattern</title>
      <link>https://danysk.github.io/portfolio/2020-fgcs/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2020-fgcs/</guid>
      <description>&lt;h4 id=&#34;highlights&#34;&gt;Highlights&lt;/h4&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Self-organising Coordination Regions (SCR) is a design pattern for decentralised self-integration in dynamic environments.&lt;/li&gt;&#xA;&lt;li&gt;SCR captures recurrent design approaches in a variety of domains including swarm control, resource management, and service orchestration.&lt;/li&gt;&#xA;&lt;li&gt;SCR consists of a dynamic process involving leader election, coalition formation, and feedback loops between leaders and subordinates.&lt;/li&gt;&#xA;&lt;li&gt;SCR can be straightforwardly implemented as continuous collective workflows in Aggregate Programming languages.&lt;/li&gt;&#xA;&lt;li&gt;SCR is versatile, as shown through case studies in edge computing and hierarchical, heterogeneous networks.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;abstract&#34;&gt;Abstract&lt;/h4&gt;&#xA;&lt;p&gt;In software engineering, knowledge about recurrent problems, along with blueprints of associated solutions for diverse design contexts, are often captured in so-called design patterns. Identifying design patterns is particularly valuable for novel and still largely unexplored application contexts such as the Internet of Things, Cyber–Physical Systems, and Edge Computing, as it would help keeping a balanced trade-off between generality and applicability, guiding the mainstream development of language mechanisms, algorithms, architectures, and supporting platforms. Based on recurrence of related solutions found in the literature, in this work we present a design pattern for self-adaptive systems, named Self-organising Coordination Regions (SCR): its goal is to organise a process of interconnecting devices into teams, to solve local tasks in cooperation. Specifically, it is a decentralised coordination pattern for partitioned integration and coordination of devices, which relies on continuous adaptivity to context change to provide resilient distributed decision-making in large-scale situated systems. It leverages the divide-and-conquer principle, partitioning (in a self-organising fashion) the network of devices into regions, where internal coordination activities are regulated via feedback/control flows among leaders and subordinate nodes. We present the pattern, provide a template implementation in the Aggregate Computing framework, and evaluate it through simulation of two case studies in edge computing and hierarchical, heterogeneous networks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From distributed coordination to field calculus and aggregate computing</title>
      <link>https://danysk.github.io/portfolio/2013-jos-alchemist/</link>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2013-jos-alchemist/</guid>
      <description>&lt;p&gt;Aggregate computing is an emerging approach to the engineering of complex coordination for distributed systems, based on viewing system interactions in terms of information propagating through collectives of devices, rather than in terms of individual devices and their interaction with their peers and environment. The foundation of this approach is the distillation of a number of prior approaches, both formal and pragmatic, proposed under the umbrella of field-based coordination, and culminating into the field calculus, a universal functional programming model for the specification and composition of collective behaviours with equivalent local and aggregate semantics. This foundation has been elaborated into a layered approach to engineering coordination of complex distributed systems, building up to pragmatic applications through intermediate layers encompassing reusable libraries of program components. Furthermore, some of these components are formally shown to satisfy formal properties like self-stabilisation, which transfer to whole application services by functional composition. In this survey, we trace the development and antecedents of field calculus, review the field calculus itself and the current state of aggregate computing theory and practice, and discuss a roadmap of current research directions with implications for the development of a broad range of distributed systems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Higher-Order Calculus of Computational Fields</title>
      <link>https://danysk.github.io/portfolio/2019-tocl/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2019-tocl/</guid>
      <description>&lt;p&gt;The complexity of large-scale distributed systems, particularly when deployed in physical space, calls for new mechanisms to address composability and reusability of collective adaptive behaviour. Computational fields have been proposed as an effective abstraction to fill the gap between the macro-level of such systems (specifying a system’s collective behaviour) and the micro-level (individual devices’ actions of computation and interaction to implement that collective specification), thereby providing a basis to better facilitate the engineering of collective APIs and complex systems at higher levels of abstraction. This article proposes a full formal foundation for field computations, in terms of a core (higher-order) calculus of computational fields containing a few key syntactic constructs, and equipped with typing, denotational and operational semantics. Critically, this allows formal establishment of a link between the micro- and macro-levels of collective adaptive systems by a result of computational adequacy and abstraction for the (aggregate) denotational semantics with respect to the (per-device) operational semantics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Engineering Resilient Collective Adaptive Systems by Self-Stabilisation</title>
      <link>https://danysk.github.io/portfolio/2018-tomacs/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2018-tomacs/</guid>
      <description>&lt;p&gt;Collective adaptive systems are an emerging class of networked computational systems particularly suited for application domains such as smart cities, complex sensor networks, and the Internet of Things. These systems tend to feature large-scale, heterogeneity of communication model (including opportunistic peer-to-peer wireless interaction) and require inherent self-adaptiveness properties to address unforeseen changes in operating conditions. In this context, it is extremely difficult (if not seemingly intractable) to engineer reusable pieces of distributed behaviour to make them provably correct and smoothly composable. Building on the field calculus, a computational model (and associated toolchain) capturing the notion of aggregate network-level computation, we address this problem with an engineering methodology coupling formal theory and computer simulation. On the one hand, functional properties are addressed by identifying the largest-to-date field calculus fragment generating self-stabilising behaviour, guaranteed to eventually attain a correct and stable final state despite any transient perturbation in state or topology and including highly reusable building blocks for information spreading, aggregation, and time evolution. On the other hand, dynamical properties are addressed by simulation, empirically evaluating the different performances that can be obtained by switching between implementations of building blocks with provably equivalent functional properties. Overall, our methodology sheds light on how to identify core building blocks of collective behaviour and how to select implementations that improve system performance while leaving overall system function and resiliency properties unchanged.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Self-Adaptation to Device Distribution in the Internet of Things</title>
      <link>https://danysk.github.io/portfolio/2017-taas/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2017-taas/</guid>
      <description>&lt;p&gt;A key problem when coordinating the behaviour of spatially situated networks, like those typically found in the Internet of Things (IoT), is adaptation to changes impacting network topology, density, and heterogeneity. Computational goals for such systems, however, are often dependent on geometric properties of the continuous environment in which the devices are situated rather than the particulars of how devices happen to be distributed through it. In this article, we identify a new property of distributed algorithms, eventual consistency, which guarantees that computation converges to a final state that approximates a predictable limit, based on the continuous environment, as the density and speed of devices increases. We then identify a large class of programs that are eventually consistent, building on prior results on the field calculus computational model that identify a class of self-stabilizing programs. Finally, we confirm through simulation of IoT application scenarios that eventually consistent programs from this class can provide resilient behavior where programs that are only converging fail badly.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Aggregate Programming for the Internet of Things</title>
      <link>https://danysk.github.io/portfolio/2015-ieee-computer/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2015-ieee-computer/</guid>
      <description>&lt;p&gt;Through field calculus constructs and building-block APIs, aggregate programming could help unlock the IoT&amp;rsquo;s true potential by allowing complex distributed services to be specified succinctly and by enabling such services to be safely encapsulated, modulated, and composed with one another.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Protelis: Practical Aggregate Programming</title>
      <link>https://danysk.github.io/portfolio/2015-sac-protelis/</link>
      <pubDate>Wed, 01 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2015-sac-protelis/</guid>
      <description>&lt;p&gt;The notion of a computational field has been proposed as a unifying abstraction for developing distributed systems, focusing on the computations and coordination of aggregates of devices instead of individual behavior. Prior field-based languages, however, have suffered from a number of practical limitations that have posed barriers to adoption and use. We address these limitations by introduction of Protelis, a functional language based on computational fields and embedded in Java, thereby enabling the construction of widely reusable components of aggregate systems. We demonstrate the simplicity of Protelis integration and programming through two examples: simulation of a pervasive computing scenario in the Alchemist simulator, and coordinated management of a network of services.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chemical-oriented simulation of computational systems with Alchemist</title>
      <link>https://danysk.github.io/portfolio/2019-jlamp/</link>
      <pubDate>Sun, 01 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://danysk.github.io/portfolio/2019-jlamp/</guid>
      <description>&lt;p&gt;In this paper we address the engineering of complex and emerging computational systems featuring situatedness, adaptivity and self-organisation, like pervasive computing applications in which humans and devices, dipped in a very mobile environment, opportunistically interact to provide and exploit information services. We adopt a meta-model in which possibly mobile, interconnected and communicating agents work according to a set of chemical-like laws. According to this view, substantiated by recent research on pervasive computing systems, we present the Alchemist simulation framework, which retains the performance of known Stochastic Simulation Algorithms for (bio)chemistry, though it is tailored to the specific features of complex and situated computational systems.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
